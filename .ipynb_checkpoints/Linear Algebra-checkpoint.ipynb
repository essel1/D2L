{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b225a14-4b0b-4222-aada-eaa0079129ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929f52c6-3268-4980-ac6f-873c67e29213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  4,  8],\n",
      "        [ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(12).reshape(3,4)\n",
    "print(A)\n",
    "print(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76345a4e-e636-4908-abcd-3537002f3503",
   "metadata": {},
   "source": [
    "### Basic Properties of Tensor Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e9dcf-62ce-4a7e-9e66-9e6cd8d9b627",
   "metadata": {},
   "source": [
    "Element wise operations regardless of the order of the tensor atleast between the same shape generate output of the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf7d89a-edd2-4cc4-b4c5-5a62e45ee4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  0,   1,   4,   9],\n",
       "          [ 16,  25,  36,  49],\n",
       "          [ 64,  81, 100, 121]],\n",
       " \n",
       "         [[144, 169, 196, 225],\n",
       "          [256, 289, 324, 361],\n",
       "          [400, 441, 484, 529]]]),\n",
       " tensor([[[ 0,  2,  4,  6],\n",
       "          [ 8, 10, 12, 14],\n",
       "          [16, 18, 20, 22]],\n",
       " \n",
       "         [[24, 26, 28, 30],\n",
       "          [32, 34, 36, 38],\n",
       "          [40, 42, 44, 46]]]),\n",
       " tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(24).reshape(2,3,4)\n",
    "B = A.clone()\n",
    "A*B, A+B, A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d369417b-cb2b-45ca-afac-765c0c8c32a7",
   "metadata": {},
   "source": [
    "A * B is the elementwise product of two matrices or tensors called **Hadamard Product**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb35c27-8b59-47be-a140-ab1719ed8357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, (A*A).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ab572c-59db-449f-9c0f-cd35b4372572",
   "metadata": {},
   "source": [
    "### Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d78d0c7-03e9-4045-9e19-f82fed8dcde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1.],\n",
       "         [2., 3.],\n",
       "         [4., 5.]], dtype=torch.float64),\n",
       " tensor(15., dtype=torch.float64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(6, dtype = float).reshape(3,2)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1051c-2f66-48b8-9d9a-f423122b8061",
   "metadata": {},
   "source": [
    "Invoking the sum function reduces a tensor along all of it's axes producing a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7450cae5-b784-4b3b-979c-3944bd0e2ff1",
   "metadata": {},
   "source": [
    "TO sum over all the elements along the rows (axis 0), we specify axis=0 in sum or axis=1 along the column wise addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e75bd6-f4df-4268-9966-4d6bfc5ddf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 9]), tensor([1, 5, 9]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(axis = 0), x.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe0fa5c-6fec-4900-a895-bdb532579e76",
   "metadata": {},
   "source": [
    "**Mean** works similar to sum as it reduces the size to a scalar or reduces to a arbitrary number if done along row(axis = 0) or columns(axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca792b-9181-4068-9afd-cfa81ae830bf",
   "metadata": {},
   "source": [
    "### Non-Reduction Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcbcf3f4-19d7-4f8c-971f-a8dc24f9ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_reduced_sum = x.sum(axis=1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d3e8e85-b771-4b51-a90e-b3af1363cd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [5],\n",
       "        [9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_reduced_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d626914-821d-43c2-8dac-1e7e74c622bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, non_reduced_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08914847-3fc0-4516-8dd4-a64dbb57c9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.0000],\n",
       "        [0.4000, 0.6000],\n",
       "        [0.4444, 0.5556]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x / non_reduced_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c4223-8b07-46c9-b908-13a469b7c5b9",
   "metadata": {},
   "source": [
    "There is another function to calculate the cumulative sum of elements of A along some axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8746294d-485f-4db3-b8e0-b68f2e43c627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 4],\n",
       "        [6, 9]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "x.cumsum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ed5bc-85de-4c4b-adde-baddae8a2fef",
   "metadata": {},
   "source": [
    "### Dot Products and Matrix-Vector Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab873315-b203-4559-9797-0c83aa87fb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(6, dtype = float).reshape(3,2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ec22013-2f55-4c07-97c0-7c79d125c6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.],\n",
       "        [ 4.,  9.],\n",
       "        [16., 25.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278d189-1453-4d00-b312-ade801a7d2d1",
   "metadata": {},
   "source": [
    "We can calculate the dot product by summing the elementwise multiplication between two tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59807e24-128b-415d-b293-54653c6d66fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55., dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603e13f-b84e-40a5-9659-a26e4819ed22",
   "metadata": {},
   "source": [
    "As for Matrix and vector products, let A be a matrix and x be a vector then, Ax is the same as the matrix-matrix mul that happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23c2aca1-2bad-468a-912f-dd97c1f9d24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c353255f-dd90-4db9-8cab-2422aa290a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(6,2,3, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "451d3866-a9bb-4c9e-9212-bc85eaac1a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0457, 2.7468],\n",
       "         [4.3119, 5.9719]],\n",
       "\n",
       "        [[1.1162, 1.9337],\n",
       "         [3.3819, 5.5209]],\n",
       "\n",
       "        [[1.8268, 3.4163],\n",
       "         [2.6845, 4.0483]],\n",
       "\n",
       "        [[0.7419, 1.3831],\n",
       "         [3.6297, 5.1229]],\n",
       "\n",
       "        [[3.4498, 5.5752],\n",
       "         [1.7135, 3.3291]],\n",
       "\n",
       "        [[1.9082, 3.5913],\n",
       "         [3.3868, 4.8114]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "262e326e-0612-42e6-9167-cc77b4355bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0947, 0.1902, 0.4163],\n",
       "          [0.2758, 0.6124, 0.7718]],\n",
       " \n",
       "         [[0.5211, 0.0349, 0.2616],\n",
       "          [0.9971, 0.5928, 0.5491]],\n",
       " \n",
       "         [[0.6935, 0.8785, 0.0175],\n",
       "          [0.5987, 0.1881, 0.5771]],\n",
       " \n",
       "         [[0.3691, 0.1732, 0.0989],\n",
       "          [0.4628, 0.2457, 0.7846]],\n",
       " \n",
       "         [[0.9954, 0.5350, 0.5949],\n",
       "          [0.9001, 0.5743, 0.1412]],\n",
       " \n",
       "         [[0.8548, 0.7023, 0.1259],\n",
       "          [0.1651, 0.8256, 0.4339]]], dtype=torch.float64),\n",
       " tensor([[0., 1.],\n",
       "         [2., 3.],\n",
       "         [4., 5.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1253f5-8ec9-4228-b587-85e799cb0231",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8ec7e46-c28a-4ee8-b396-2761edcff54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]], dtype=torch.float64),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype = float).reshape(2,3)\n",
    "B = torch.ones(3,2, dtype = float)\n",
    "\n",
    "A,B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38039f69-cd58-4038-b736-c865545e00de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.,  3.],\n",
       "         [12., 12.]], dtype=torch.float64),\n",
       " tensor([[ 3.,  3.],\n",
       "         [12., 12.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(A,B), A@B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285724b-b257-44c7-b6e0-eb6327715353",
   "metadata": {},
   "source": [
    "### Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eca577-a6af-4879-966b-aaf05be906a7",
   "metadata": {},
   "source": [
    "Informally, the norm of a vector tells us how big it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184fc71a-0c14-4648-bd95-457d04b6a374",
   "metadata": {},
   "source": [
    "A norm is a function ||.|| that maps a vector to a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8b136-8ffe-494f-9654-9adb79086d9a",
   "metadata": {},
   "source": [
    "To calculate the l2 norm we call the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e99290c3-90a0-42f5-a7f0-cbd534b75e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8284)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([2.0,-2.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed14ed-20b2-4c4e-833f-61c730051a5a",
   "metadata": {},
   "source": [
    "As for the l1 norm, we compose the absolute values with the sum operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29324aa4-f5c2-4365-a1a9-a05a52ecc8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26790e83-4a99-4568-a5c2-decf267abae4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d31dc6-ccfa-4df6-b686-21535760f88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
