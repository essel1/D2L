{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fab1286-c970-459c-b80d-fd62b6f98e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbae45-a8b3-4024-a410-1742cc77b480",
   "metadata": {},
   "source": [
    "### Data Creation and data info gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad202c-1d17-4648-98c0-0a28250f488b",
   "metadata": {},
   "source": [
    "By invoking arange(n), we can create a vector of evenly spaced values, starting at 0 and ending at n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8babfdd-7ebc-4ae0-a38c-b5eedff5f8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12, dtype = torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f95b9-786f-4d88-81a1-ee0965347210",
   "metadata": {},
   "source": [
    "**numel** method is like the len operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb947cd-5f3a-40d1-b66b-e06260fd8a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44de37b-aa97-4f63-b2f2-024bb55280ec",
   "metadata": {},
   "source": [
    "Similar to the **shape** method in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bdc950f-a28c-408b-8ecb-08e5eb22bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108920c8-b0d6-46d8-9005-78c19624bb3c",
   "metadata": {},
   "source": [
    "And, the **reshape** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8e112a-7cca-4759-81aa-0f6a96bf5cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(4,3)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a552c99-6916-4603-92e1-a37f93f14b75",
   "metadata": {},
   "source": [
    "And the same is for initializing **zeros** and **ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa2b6b84-a133-410a-96d0-6eb2bd9896c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2,3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f41b31-1062-4d81-9dbf-9a37a78b43f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a187e8f-edb1-444b-a93f-4a72d3ec0a15",
   "metadata": {},
   "source": [
    "And, we can sample each element randomly from a given probability distribution. The following snippet creates a tensor with elements from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14808fe5-4e40-4914-b15d-d495e2ec6b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0742, -0.6094,  0.1738],\n",
       "        [ 0.1788,  0.8581,  1.5082],\n",
       "        [ 0.7539,  0.9711,  0.4537]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435787d5-6084-479b-894f-9555ef32c306",
   "metadata": {},
   "source": [
    "And, Finally we can construct tensors by providing the elements we need by initializing them inside a python lists containing numerical literals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68369f7f-dc25-4aad-bc12-ed047bbaaf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 9, 9]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3],[4,5,6],[7,9,9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f13b4a-0de1-468c-9083-a49742401f38",
   "metadata": {},
   "source": [
    "### Indexing and Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35abeada-3386-4c06-92bc-b2d0ffc436c3",
   "metadata": {},
   "source": [
    "Accessing tensor elements is very similar to how you access elements inside a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "487dbcf1-b449-4a0d-a262-53d9c2528d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 10., 11.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e570d813-817c-41bf-bec1-9beef6afcc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f2f9c6-c79b-4886-940d-3a378b6e583d",
   "metadata": {},
   "source": [
    "We can acess a particular element by specifying the various dimension inside the tensor like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07509b97-d032-4f2d-bd9d-f0edf53f85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0,2] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57f3f4ea-2fdd-41bf-8ef7-e841203be192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1., 999.],\n",
       "        [  3.,   4.,   5.],\n",
       "        [  6.,   7.,   8.],\n",
       "        [  9.,  10.,  11.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d982339-c8ba-4a39-92fa-fc39ff0fb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:3,:] = 888."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42175c5b-baaf-47ca-86f4-eebc986d16cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[888., 888., 888.],\n",
       "        [888., 888., 888.],\n",
       "        [888., 888., 888.],\n",
       "        [  9.,  10.,  11.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ada1313-8e64-46fb-a891-6d8e9f6132a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c03824-8619-463d-889e-a74267f72ff3",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9ca9e-2b87-4cd4-9bff-9a828d6816fd",
   "metadata": {},
   "source": [
    "Most standard operators such as unary operator like e^x can be applied elementwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8184567a-5a4a-4e5c-b364-47f9142915b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([       inf,        inf,        inf,        inf,        inf,        inf,\n",
       "               inf,        inf,        inf,  8103.0840, 22026.4648, 59874.1406])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c09a23e-29ea-4991-9e95-908cda8e46e1",
   "metadata": {},
   "source": [
    "As for the binary scalar operations, we can produce a new vector or tensor from providing two tensors of the same shape. These also happen elementwise for identically shaped tensors of arbitrary shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad7eeb38-6ac3-4c18-b55f-f50ec8ac357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones(2,3)\n",
    "B = torch.ones(2,3)\n",
    "A = A + B\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fd50b45-2405-4010-9bd3-2addb35ef9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[2., 2., 2.],\n",
       "         [2., 2., 2.]]),\n",
       " tensor([[2., 2., 2.],\n",
       "         [2., 2., 2.]]),\n",
       " tensor([[2., 2., 2.],\n",
       "         [2., 2., 2.]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A-B, A*B, A**B, A/B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693cd15-9feb-489e-ba5a-1205f08ca9e1",
   "metadata": {},
   "source": [
    "In addition to unary or binary single element-wise operations, we can also perform linear algebric operations like dot product or matrix multiplication. More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfbea70-ed09-4d72-a21d-4e01fa8821a0",
   "metadata": {},
   "source": [
    "Additionally, we can concatenate multiple tensors, stacking them end-to-end to form a larger one. After providing a list of tensors, we can tell the system axis through which to concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60dc76cf-b2ac-4ab8-9e83-3d0d51922d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  0.,  0.,  0.,  0.],\n",
       "         [ 4.,  5.,  6.,  7.,  0.,  0.,  0.,  0.],\n",
       "         [ 8.,  9., 10., 11.,  0.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype = torch.float32).reshape(3,4)\n",
    "Y = torch.zeros(3,4)\n",
    "torch.cat((X,Y), dim = 0), torch.cat((X,Y), dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d38123-36a8-4ad4-9927-8d71d5eafef4",
   "metadata": {},
   "source": [
    "We can also contruct a binary tensors via logical statements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8bb03aa-b034-4fda-9799-12d74a743070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boo = (X <= Y)\n",
    "boo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85926195-99f5-41db-b0be-8540b95d2534",
   "metadata": {},
   "source": [
    "And we can sum the whole tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee6405eb-a9bc-4c6e-9384-92b10788cbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(120.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdbf783c-4373-4742-9adf-981efc282edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boo.sum()  # although boo waas a tensors of True or False, it treated True as 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b400fef-f13a-4efb-80e7-2dad646ff855",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be77ec-2ff8-435b-be31-cf1010987745",
   "metadata": {},
   "source": [
    "Under certain conditions, even though when shapes differ, we can still perform elementwise binary opeartions by invoking the **broadcasting** mechanism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aef144ef-304a-429e-a861-1c8a827509ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]),\n",
       " tensor([0, 1, 2]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(6).reshape(2,3)\n",
    "b = torch.arange(3)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed690ba4-ba2c-414c-8c07-8af283b63f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [3, 5, 7]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12de33-cdec-4bdc-8056-84a5dd4119d8",
   "metadata": {},
   "source": [
    "### Saving Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0e5e3-1595-4dc1-b49b-9f66db2809da",
   "metadata": {},
   "source": [
    "Running operations can cause new memory to be allocated to host results. We want to save memory so we want to update the variable pointing to the tensor in place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "880bd1a6-5a71-4831-b719-ba86769ccecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(a)\n",
    "a = a+b\n",
    "before == id(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aeb8af-db99-4288-9f7a-3bec70fd5bff",
   "metadata": {},
   "source": [
    "We need to update the variables in place for two mainly two reasons:\n",
    "- we have multiple parameters that are updated per very small unit time so allocating new memory for each isn't efficient and very costly\n",
    "- Multiple other variables might be pointiing to a single variable and we need to update the references if we don't update in place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bfe4a4-66f3-4136-8466-9309bcf8350f",
   "metadata": {},
   "source": [
    "We can use slice notation to perform in-place operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "817a4e2e-8b18-4e79-b430-19c3835d4468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(a)\n",
    "a[:] = a+b \n",
    "before == id(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aad001-a61b-429c-9b1a-1d101f2dafdb",
   "metadata": {},
   "source": [
    "Alternatively, we can use operators like this instead of slicing too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05c73073-6f1f-45bb-9c66-c8b651966ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(a)\n",
    "a =+ b\n",
    "before == id(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12416fee-a34f-493f-aa6f-725fe5db2d61",
   "metadata": {},
   "source": [
    "### Conversion to other Python Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3842a8-1472-46b3-8fa3-ebfaf146c64f",
   "metadata": {},
   "source": [
    "We can change from a numpy darray to tensor and vice versa and they share the same memory. So, changing them with in-place operator will change the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1176546-ef3a-4bcc-a0da-a8f57c164488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1871462109456 1871461732816\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.zeros(5)\n",
    "B = torch.from_numpy(A)\n",
    "print(id(A), id(B))\n",
    "print(id(A) == id (B))\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1cf685-b4af-47de-a05a-9ecff2977b0e",
   "metadata": {},
   "source": [
    "To convert a size-1 tensor to a python scalar, we can invoke the **item** function or python's in-built functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a56230d7-8553-438e-a54d-ddb0fbfd9d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1]), 1, 1.0, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([1])\n",
    "y,y.item(),float(y), int(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f08adb-46f0-4e54-a52b-a8355c54b264",
   "metadata": {},
   "source": [
    "### Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e9cc38d5-fea8-4198-af88-3ed6501d9086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]]),\n",
       " tensor([[[1.]],\n",
       " \n",
       "         [[1.]]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_1 = torch.ones(2,3,5)\n",
    "b_1 = torch.ones(2,1,1)\n",
    "a_1,b_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64c50746-548a-4527-bc34-d0132c862a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_1 + b_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
