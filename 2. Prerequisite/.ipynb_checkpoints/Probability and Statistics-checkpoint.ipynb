{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e91435d-3bdc-4729-abf8-a29a84d21e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.distributions.multinomial import Multinomial\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e267f",
   "metadata": {},
   "source": [
    "Statistics are empirical quantities that are computed as functions of the observed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8cee3d",
   "metadata": {},
   "source": [
    "We often design special statistics called **estimators** that, given a dataset, produce estimates of model parameters such as probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bdbd4",
   "metadata": {},
   "source": [
    "Moreover, when those estimators satisfy a nice property called *consistency*, our estimates will converge to the corresponding probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24902724",
   "metadata": {},
   "source": [
    "Drawing realizations from some underlying random process is called **sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92f7bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads,tails: [47, 53]\n"
     ]
    }
   ],
   "source": [
    "num_tosses = 100\n",
    "heads = sum([random.random() > 0.5 for i_ in range(num_tosses)])\n",
    "tails = num_tosses - heads\n",
    "print(\"heads,tails:\", [heads, tails])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d75f2b",
   "metadata": {},
   "source": [
    "More generally, we can simulate multiple draws from any variable with a finite number of possible outcomes by calling the multinomial function setting the first argument to the number of draws and the second as a list of probabilities associated with each of the possible outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04608cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([54., 46.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_probs = torch.tensor([0.5,0.5])\n",
    "Multinomial(100,fair_probs).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c931aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5200, 0.4800])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Multinomial(100,fair_probs).sample() / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08708e3a",
   "metadata": {},
   "source": [
    "How could we know if the simulation or the probabilites are skewed or the possible deviation from theoritical probabilites was just an artifact of the small sample size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66990aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4996, 0.5004])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Multinomial(100000, fair_probs).sample() / 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd704571",
   "metadata": {},
   "source": [
    "In general, for averages of repeated events, as the number of repetitions grows, our estimates are guaranteed to converge to the true underlying probabilites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185096de",
   "metadata": {},
   "source": [
    "THis mathematical formulation of this phenomenon is called the law of *large numbers* and the **central limit theorem** tells us that in many situations, as the sample size n grows, these errors should go down at a rate of (1/n^0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "389c55a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (4130479334.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    d2l.plt.plot(estimates[:,1]), label = (\"P(coin=tails)\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "counts = Multinomial(1,fair_probs).sample((10000,))\n",
    "cum_counts = counts.cumsum(dim=0)\n",
    "print(cum_counts)\n",
    "estimates = cum_counts/cum_counts.sum(dim=1, keepdims=True)\n",
    "estimates = estimates.numpy()\n",
    "\n",
    "d2l.set_figsize((4.5,3.5))\n",
    "d2l.plt.plot(estimates[:,0], label=(\"P(coin=heads)\"))\n",
    "d2l.plt.plot(estimates[:,1]), label = (\"P(coin=tails)\")\n",
    "d2l.plt.axhline(y=0.5, color=\"black\",linestyle = \"dashed\")\n",
    "d2l.plt.gca().set_xlabel(\"Samples\")\n",
    "d2l.plt.gca().set_ylabel(\"Estimated Probabilites\")\n",
    "d2l.plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637a90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
